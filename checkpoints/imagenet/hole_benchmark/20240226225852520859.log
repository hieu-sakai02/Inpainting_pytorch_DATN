2024-02-26 22:58:52,520 INFO Arguments: Namespace(config='configs/config.yaml', seed=None)
2024-02-26 22:58:52,521 INFO Random seed: 9124
2024-02-26 22:58:52,522 INFO Configuration: {'dataset_name': 'imagenet', 'data_with_subfolder': True, 'train_data_path': './datasets/ImageNet/ILSVRC2012_img_train/', 'val_data_path': None, 'resume': None, 'batch_size': 12, 'image_shape': [256, 256, 3], 'mask_shape': [128, 128], 'mask_batch_same': True, 'max_delta_shape': [32, 32], 'margin': [0, 0], 'discounted_mask': True, 'spatial_discounting_gamma': 0.9, 'random_crop': True, 'mask_type': 'hole', 'mosaic_unit_size': 12, 'expname': 'benchmark', 'cuda': True, 'gpu_ids': [0], 'num_workers': 4, 'lr': 0.0001, 'beta1': 0.5, 'beta2': 0.9, 'n_critic': 5, 'niter': 500000, 'print_iter': 100, 'viz_iter': 1000, 'viz_max_out': 16, 'snapshot_save_iter': 5000, 'coarse_l1_alpha': 1.2, 'l1_loss_alpha': 1.2, 'ae_loss_alpha': 1.2, 'global_wgan_loss_alpha': 1.0, 'gan_loss_alpha': 0.001, 'wgan_gp_lambda': 10, 'netG': {'input_dim': 3, 'ngf': 32}, 'netD': {'input_dim': 3, 'ndf': 64}}
2024-02-26 22:58:52,522 INFO Training on dataset: imagenet
2024-02-26 22:59:02,103 INFO 
Generator(
  (coarse_generator): CoarseGenerator(
    (conv1): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(5, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (conv2_downsample): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (conv3): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv4_downsample): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (conv5): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv6): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv7_atrous): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
    )
    (conv8_atrous): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
    )
    (conv9_atrous): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))
    )
    (conv10_atrous): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16))
    )
    (conv11): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv12): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv13): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv14): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv15): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv16): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv17): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (conv): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (fine_generator): FineGenerator(
    (conv1): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(5, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (conv2_downsample): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (conv3): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv4_downsample): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (conv5): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv6): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv7_atrous): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
    )
    (conv8_atrous): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
    )
    (conv9_atrous): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))
    )
    (conv10_atrous): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16))
    )
    (pmconv1): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(5, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (pmconv2_downsample): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (pmconv3): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (pmconv4_downsample): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (pmconv5): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (pmconv6): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ReLU(inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (contextul_attention): ContextualAttention()
    (pmconv9): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (pmconv10): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (allconv11): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (allconv12): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (allconv13): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (allconv14): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (allconv15): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (allconv16): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (allconv17): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (conv): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
)
2024-02-26 22:59:02,107 INFO 
LocalDis(
  (dis_conv_module): DisConvModule(
    (conv1): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv2): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv3): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv4): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
  )
  (linear): Linear(in_features=16384, out_features=1, bias=True)
)
2024-02-26 22:59:02,108 INFO 
GlobalDis(
  (dis_conv_module): DisConvModule(
    (conv1): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv2): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv3): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv4): Conv2dBlock(
      (pad): ZeroPad2d((0, 0, 0, 0))
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
  )
  (linear): Linear(in_features=65536, out_features=1, bias=True)
)
2024-02-26 23:00:33,319 ERROR CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.46 GiB is allocated by PyTorch, and 251.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
